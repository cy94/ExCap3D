# @package data
train_dataset:
  _target_: datasets.semseg.SemanticSegmentationDataset
  dataset_name: "scannet"
  data_dir: ${data.data_dir}
  image_augmentations_path: conf/augmentation/albumentations_aug.yaml
  volume_augmentations_path: conf/augmentation/volumentations_aug.yaml
  data_percent: 1.0
  mode: ${data.train_mode}
  ignore_label: ${data.ignore_label}
  num_labels: ${data.num_labels}
  add_raw_coordinates: ${data.add_raw_coordinates}
  add_colors: ${data.add_colors}
  add_normals: ${data.add_normals}
  add_instance: ${data.add_instance}
  # different augs experiments
  instance_oversampling: 0.0
  place_around_existing: false
  point_per_cut: 0
  max_cut_region: 0
  flip_in_center: false
  noise_rate: 0
  resample_points: 0
  add_unlabeled_pc: false
  cropping: ${data.cropping}
  cropping_args: ${data.cropping_args}
  is_tta: false
  crop_min_size: ${data.crop_min_size}
  crop_length: ${data.crop_length}
  filter_out_classes: [0, 1]
  label_offset: 2
  overfit: ${data.overfit}
  overfit_n_instances: ${data.overfit_n_instances}
  overfit_instance_ids: ${data.overfit_instance_ids}
  clip_points: 300000
  subset: ${data.subset}
  # keep only these instance classes, make rest as ignore label
  keep_instance_classes_file: ${data.instance_classes_file}
  # turn of all augmentations and random changes to the data, makes train dataset like val
  no_aug: false
  list_file: null
  repeat: null
  #### CAPTIONING ####
  gen_captions: ${general.gen_captions}
  gen_part_captions: ${general.gen_part_captions}
  caption_data_dir: ${data.caption_data_dir}
  max_caption_length: ${general.max_caption_length}
  semlabel_caption: ${general.semlabel_caption}
  exclude_scenes_without_caption: ${general.exclude_scenes_without_caption}
  tokenizer_model_name: ${caption_model.tokenizer_model_name}
  obj_caption_key: ${general.obj_caption_key}
  part_caption_key: ${general.part_caption_key}
  caption_no_aug: false
  max_caption_aug: null
  extra_feats_dir:  ${data.extra_feats_dir}
  extra_feats_dim: ${data.extra_feats_dim}
  # scannet - use the otherprop and otherstructure classes for training and evaluation
  scannet_use_others_class: ${data.scannet_use_others_class}

validation_dataset:
  _target_: datasets.semseg.SemanticSegmentationDataset
  dataset_name: "scannet"
  data_dir: ${data.data_dir}
  image_augmentations_path: null
  volume_augmentations_path: null
  data_percent: 1.0
  mode: ${data.validation_mode}
  ignore_label: ${data.ignore_label}
  num_labels: ${data.num_labels}
  add_raw_coordinates: ${data.add_raw_coordinates}
  add_colors: ${data.add_colors}
  add_normals: ${data.add_normals}
  add_instance: ${data.add_instance}
  cropping: false
  is_tta: false
  crop_min_size: ${data.crop_min_size}
  crop_length: ${data.crop_length}
  filter_out_classes: [0, 1]
  label_offset: 2
  overfit: ${data.overfit}
  overfit_n_instances: ${data.overfit_n_instances}
  overfit_instance_ids: ${data.overfit_instance_ids}
  clip_points: 0
  subset: ${data.subset}
  # keep only these instance classes, make rest as ignore label
  keep_instance_classes_file: ${data.instance_classes_file}
  no_aug: true
  list_file: null
  repeat: null
  #### CAPTIONING ####
  gen_captions: ${general.gen_captions}
  gen_part_captions: ${general.gen_part_captions}
  caption_data_dir: ${data.caption_data_dir}
  max_caption_length: ${general.max_caption_length}
  semlabel_caption: ${general.semlabel_caption}
  exclude_scenes_without_caption: ${general.exclude_scenes_without_caption}
  tokenizer_model_name: ${caption_model.tokenizer_model_name}
  obj_caption_key: ${general.obj_caption_key}
  part_caption_key: ${general.part_caption_key}
  caption_no_aug: true # dont augment captions in val
  max_caption_aug: 1
  extra_feats_dir: ${data.extra_feats_dir}
  extra_feats_dim: ${data.extra_feats_dim}
  # scannet - use the otherprop and otherstructure classes for training and evaluation
  scannet_use_others_class: ${data.scannet_use_others_class}